{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8c0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from opensoundscape.ml.cnn import load_model\n",
    "import sklearn\n",
    "from glob import glob\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "#set up plotting\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# opensoundscape transfer learning tools\n",
    "from opensoundscape.ml.shallow_classifier import MLPClassifier, quick_fit, fit_classifier_on_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53455381",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"data/birdset_effnetB1_finetuned_19cls.model\"   # your saved model\n",
    "TRAIN_LABELS_CSV = \"data/train_labels_5s_mac_frommeta.csv\"\n",
    "TEST_LABELS_CSV = \"data/test_labels_5s_mac_frommeta.csv\"\n",
    "VAL_LABELS_CSV = \"data/val_labels_5s_mac.csv\"\n",
    "OUT_PRED_CSV = \"data/preds_val_birdset_finetuned.csv\"       # optional\n",
    "OUT_AP_AUROC_CSV = \"/Volumes/Expansion/Evaluation/AP_AUROC_birdset_finetuned.csv\"\n",
    "filename = 'birdset_effnetB1_finetuned_19cls'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9fa87ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1476, 19) 19\n"
     ]
    }
   ],
   "source": [
    "train_labels = pd.read_csv(TRAIN_LABELS_CSV, index_col = [0,1,2])\n",
    "val_labels = pd.read_csv(VAL_LABELS_CSV, index_col = [0,1,2])\n",
    "test_labels = pd.read_csv(TEST_LABELS_CSV, index_col = [0,1,2])\n",
    "val_labels.head()\n",
    "\n",
    "# pick classes for predictions\n",
    "class_list = val_labels.columns.tolist()\n",
    "\n",
    "print(val_labels.shape, len(class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f1d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from save path\n",
    "from opensoundscape.ml.cnn import load_model\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5824f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0234fcff1e5b42b6a57b72179a0439e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1476 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sholmes3/miniforge3/envs/rewilding_pytorch_mac/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1476, 19)\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(val_labels)\n",
    "\n",
    "# Ensure it's a DataFrame with correct index/columns\n",
    "if not isinstance(preds, pd.DataFrame):\n",
    "    preds = pd.DataFrame(preds, index=val_labels.index, columns=class_list)\n",
    "else:\n",
    "    preds = preds[class_list].loc[val_labels.index]\n",
    "\n",
    "print(preds.shape)\n",
    "preds.to_csv(OUT_PRED_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "968d31cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        species  avg_precision_score  auroc_score\n",
      "0   Hypsipetes_madagascariensis             0.810638     0.880609\n",
      "1      Copsychus_albospecularis             0.499097     0.912956\n",
      "2              Coracopsis_nigra             0.277712     0.906065\n",
      "3           Dicrurus_forficatus             0.385287     0.879804\n",
      "4                 Coua_caerulea             0.016213     0.401273\n",
      "5      Zosterops_maderaspatanus             0.762630     0.982265\n",
      "6          Eurystomus_glaucurus             0.058483     0.879305\n",
      "7               Agapornis_canus             0.005778     0.397408\n",
      "8            Saxicola_torquatus             0.008757     0.395976\n",
      "9    Cyanolanius_madagascarinus             0.005869     0.724015\n",
      "10          Leptopterus_chabert             0.004794     0.214272\n",
      "11          Nesoenas_picturatus             0.000000          NaN\n",
      "12               Coua_reynaudii             0.000000          NaN\n",
      "13          Ceblepyris_cinereus             0.001952     0.474559\n",
      "14        Neodrepanis_coruscans             0.006490     0.456212\n",
      "15          Philepitta_castanea             0.002972     0.346431\n",
      "16                   Eulemur_sp             0.012837     0.620464\n",
      "17                Coua_cristata             0.000000          NaN\n",
      "18             Treron_australis             0.001828     0.629831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/tdx88v0j3nxc98khlqvpflxw0000gr/T/ipykernel_21951/2524298106.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  avprecscore_auroc_by_sp = pd.concat([avprecscore_auroc_by_sp, new_row], ignore_index=True)\n",
      "/Users/sholmes3/miniforge3/envs/rewilding_pytorch_mac/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/sholmes3/miniforge3/envs/rewilding_pytorch_mac/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/sholmes3/miniforge3/envs/rewilding_pytorch_mac/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/sholmes3/miniforge3/envs/rewilding_pytorch_mac/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/sholmes3/miniforge3/envs/rewilding_pytorch_mac/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/sholmes3/miniforge3/envs/rewilding_pytorch_mac/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "avprecscore_auroc_by_sp = pd.DataFrame(columns=['species', 'avg_precision_score','auroc_score'])\n",
    "for species in class_list:\n",
    "    avgscore = sklearn.metrics.average_precision_score(val_labels [species],preds [species])\n",
    "    auroc = sklearn.metrics.roc_auc_score(val_labels[species],preds [species])\n",
    "    new_row = pd.DataFrame({'species': [species], 'avg_precision_score': [avgscore], 'auroc_score': [auroc]})\n",
    "    avprecscore_auroc_by_sp = pd.concat([avprecscore_auroc_by_sp, new_row], ignore_index=True)\n",
    "\n",
    "print(avprecscore_auroc_by_sp)\n",
    "avprecscore_auroc_by_sp.to_csv(OUT_AP_AUROC_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63207a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set up plotting\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#write a loop to cycle through the class list and save histograms for each species for the model read in at the top of this notebook\n",
    "path = '/Volumes/Expansion/Evaluation/histograms'\n",
    "for species in class_list:\n",
    "    speciespred = species + 'pred'\n",
    "    scores_valid_df = val_labels.join(preds, rsuffix=\"pred\")\n",
    "    # Filter\n",
    "    df_Pos = scores_valid_df[scores_valid_df[species] == True] #or whatever your class of interest is called\n",
    "    df_NOT = scores_valid_df[scores_valid_df[species] == False]\n",
    "    # Plot histograms\n",
    "    plt.hist(df_NOT[speciespred],bins=20,alpha=0.5,label='negatives')\n",
    "    plt.hist(df_Pos[speciespred],bins=20,alpha=0.5,label='positives')\n",
    "    # Add a legend and labels\n",
    "    plt.legend()\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    # Show the plot\n",
    "    plt.savefig(f'/Volumes/Expansion/Evaluation/histograms/{filename}_{species}.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up plotting on log scale on y axis - easier to see small sample sizes\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#write a loop to cycle through the class list and save histograms for each species for the model read in at the top of this notebook\n",
    "path = '/Volumes/Expansion/Evaluation/histograms'\n",
    "for species in class_list:\n",
    "    speciespred = species + 'pred'\n",
    "    scores_valid_df = val_labels.join(preds, rsuffix=\"pred\")\n",
    "    # Filter\n",
    "    df_Pos = scores_valid_df[scores_valid_df[species] == True] #or whatever your class of interest is called\n",
    "    df_NOT = scores_valid_df[scores_valid_df[species] == False]\n",
    "    # Plot histograms\n",
    "    plt.hist(df_NOT[speciespred],bins=20,alpha=0.5,label='negatives')\n",
    "    plt.hist(df_Pos[speciespred],bins=20,alpha=0.5,label='positives')\n",
    "    # Add a legend and labels\n",
    "    plt.legend()\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.semilogy()\n",
    "    # Save the plot\n",
    "    plt.savefig(f'/Volumes/Expansion/Evaluation/histograms/semilog/{filename}_{species}.png')\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rewilding_pytorch_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
