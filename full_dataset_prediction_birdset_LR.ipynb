{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import bioacoustics_model_zoo as bmz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19362abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CONFIG ======\n",
    "SITE_CSV = \"data/ankafobe_forest_A_KBF01_5s.csv\"   # your site manifest\n",
    "MODEL_JOBLIB = \"data/shallow_lr_birdset_effnetB1.joblib\"  # or resample base LR\n",
    "LABELS_CSV = \"data/train_labels_5s_mac_frommeta.csv\"    # for class order\n",
    "OUT_DIR = Path(\"/Volumes/Expansion/active_learning_candidates\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BATCH_ROWS = 5000          # how many 5s clips per embed batch (tune)\n",
    "EMBED_BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# choose which species to target (recommend: rare + mid classes)\n",
    "TARGET_SPECIES = [\n",
    "    \"Philepitta_castanea\",\n",
    "    \"Treron_australis\",\n",
    "    \"Agapornis_canus\",\n",
    "    \"Saxicola_torquatus\",\n",
    "    # add more...\n",
    "]\n",
    "\n",
    "TOPK = 10000  # keep this many best clips per class\n",
    "# ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier + class list\n",
    "clf = joblib.load(MODEL_JOBLIB)\n",
    "classes = pd.read_csv(LABELS_CSV, index_col=[0,1,2]).columns.tolist()\n",
    "\n",
    "# load site clip list\n",
    "site = pd.read_csv(SITE_CSV)\n",
    "\n",
    "# make sure we have file/start/end\n",
    "needed = {\"file\",\"start_time\",\"end_time\"}\n",
    "if not needed.issubset(set(site.columns)):\n",
    "    raise ValueError(f\"{SITE_CSV} must contain columns {needed}. Found: {site.columns.tolist()}\")\n",
    "\n",
    "site = site.set_index([\"file\",\"start_time\",\"end_time\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc77295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy label df for embed()\n",
    "infer_df = pd.DataFrame(0, index=site.index, columns=classes)\n",
    "\n",
    "m = bmz.BirdSetEfficientNetB1()\n",
    "\n",
    "# container for top-K candidates per class\n",
    "top_tables = {sp: pd.DataFrame(columns=[\"file\",\"start_time\",\"end_time\",\"score\"]) for sp in TARGET_SPECIES}\n",
    "def update_topk(df_old, df_new, k):\n",
    "    df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    df = df.sort_values(\"score\", ascending=False).head(k)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48377e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process in row-batches to keep memory bounded\n",
    "idx = infer_df.index\n",
    "n = len(idx)\n",
    "for start in range(0, n, BATCH_ROWS):\n",
    "    end = min(start + BATCH_ROWS, n)\n",
    "    batch_df = infer_df.iloc[start:end]\n",
    "\n",
    "    X = m.embed(batch_df, batch_size=EMBED_BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "    p = clf.predict_proba(X.values.astype(np.float32))\n",
    "    p_df = pd.DataFrame(p, index=X.index, columns=classes)\n",
    "\n",
    "    # update candidate tables\n",
    "    for sp in TARGET_SPECIES:\n",
    "        if sp not in p_df.columns:\n",
    "            continue\n",
    "        s = p_df[sp]\n",
    "        # keep rows above a small threshold to reduce churn (optional)\n",
    "        s = s[s > 0.2]\n",
    "        if len(s) == 0:\n",
    "            continue\n",
    "        new = s.reset_index()\n",
    "        new.columns = [\"file\",\"start_time\",\"end_time\",\"score\"]\n",
    "        top_tables[sp] = update_topk(top_tables[sp], new, TOPK)\n",
    "\n",
    "    print(f\"processed rows {start}:{end} / {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results\n",
    "site_name = Path(SITE_CSV).stem\n",
    "for sp, tbl in top_tables.items():\n",
    "    out = OUT_DIR / f\"{site_name}__{sp}__top{TOPK}.csv\"\n",
    "    tbl.to_csv(out, index=False)\n",
    "\n",
    "print(\"done:\", site_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rewilding_pytorch_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
